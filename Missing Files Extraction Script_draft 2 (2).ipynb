{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24f3be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 Extract .7z zip files\n",
    "import os\n",
    "import py7zr\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_7z_file(zip_path, output_folder, password):\n",
    "    with py7zr.SevenZipFile(zip_path, mode='r', password=password) as archive:\n",
    "        archive.extractall(output_folder)\n",
    "\n",
    "def extract_and_organize(zip_folder, output_base_folder, password):\n",
    "    zip_folder = Path(zip_folder)\n",
    "    output_base_folder = Path(output_base_folder)\n",
    "\n",
    "    # Ensure the output base folder exists\n",
    "    output_base_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Process each .7z file in the zip folder\n",
    "    for zip_file in zip_folder.glob('*.7z'):\n",
    "        # Extract folder name from the .7z file (excluding the extension)\n",
    "        folder_name = zip_file.stem\n",
    "\n",
    "        # Create an output folder based on the extracted folder name\n",
    "        output_folder = output_base_folder / folder_name\n",
    "        output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Extract the .7z file to the corresponding output folder\n",
    "        extract_7z_file(zip_file, output_folder, password)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the path to the folder containing .7z files\n",
    "    zip_folder_path = \"C:/Users/Praful Bhoyar/Desktop/sam missing\"\n",
    "\n",
    "    # Set the path to the base folder where extracted files will be organized\n",
    "    output_base_folder_path = \"C:/Users/Praful Bhoyar/Desktop/extracted7z\"\n",
    "\n",
    "    # Set the common password for all .7z files\n",
    "    common_password = \"6604667cd6f4785f728bbcefa0979ddde53ad134f06191ec0525990d153bcbe5\"\n",
    "\n",
    "    # Extract and organize the files\n",
    "    extract_and_organize(zip_folder_path, output_base_folder_path, common_password)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "283cf4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Extract the nested files\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "def extract_zip_files(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.zip'):\n",
    "                zip_path = os.path.join(root, file)\n",
    "                extract_path = os.path.splitext(zip_path)[0]  # Remove the .zip extension\n",
    "                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(extract_path)\n",
    "                extract_zip_files(extract_path)  # Recursively extract nested zip files\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_directory = \"C:/Users/Praful Bhoyar/Desktop/extracted7z\"\n",
    "    extract_zip_files(input_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b3b3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directory</th>\n",
       "      <th>filename</th>\n",
       "      <th>status</th>\n",
       "      <th>SharepointPath</th>\n",
       "      <th>Zipfile</th>\n",
       "      <th>S3_size</th>\n",
       "      <th>S3_unit</th>\n",
       "      <th>S3_dttm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00532A5F2F9B46039C7E</td>\n",
       "      <td>00532A5F2F9B46039C7E_473F327E359732989D991500F...</td>\n",
       "      <td>not in S3</td>\n",
       "      <td>Lizzy's Downloads pages 1 to 12</td>\n",
       "      <td>extract_images_p0086903ui5v_20230706203430-1@1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000746ED3DF24C09AA1B</td>\n",
       "      <td>000746ED3DF24C09AA1B_512283C08D4F3A6281357A43B...</td>\n",
       "      <td>not in S3</td>\n",
       "      <td>Lizzy's Downloads pages 1 to 12</td>\n",
       "      <td>extract_images_p0086903ui5v_20230706203430-1@1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>002820D90BD049028CAC.zip</td>\n",
       "      <td>not in S3</td>\n",
       "      <td>Lizzy's Downloads pages 1 to 12</td>\n",
       "      <td>extract_images_p0086903ui5v_20230706203430-1@1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002AF2DF5F2A444E97C5</td>\n",
       "      <td>002AF2DF5F2A444E97C5_53880754D03B313D84609CC22...</td>\n",
       "      <td>not in S3</td>\n",
       "      <td>Lizzy's Downloads pages 1 to 12</td>\n",
       "      <td>extract_images_p0086903ui5v_20230706203430-1@1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004ED2DC636C4886BD30</td>\n",
       "      <td>004ED2DC636C4886BD30_3F9ED562770038E0AEC1E71C4...</td>\n",
       "      <td>not in S3</td>\n",
       "      <td>Lizzy's Downloads pages 1 to 12</td>\n",
       "      <td>extract_images_p0086903ui5v_20230706203430-1@1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              directory                                           filename  \\\n",
       "0  00532A5F2F9B46039C7E  00532A5F2F9B46039C7E_473F327E359732989D991500F...   \n",
       "1  000746ED3DF24C09AA1B  000746ED3DF24C09AA1B_512283C08D4F3A6281357A43B...   \n",
       "2                                                 002820D90BD049028CAC.zip   \n",
       "3  002AF2DF5F2A444E97C5  002AF2DF5F2A444E97C5_53880754D03B313D84609CC22...   \n",
       "4  004ED2DC636C4886BD30  004ED2DC636C4886BD30_3F9ED562770038E0AEC1E71C4...   \n",
       "\n",
       "      status                   SharepointPath  \\\n",
       "0  not in S3  Lizzy's Downloads pages 1 to 12   \n",
       "1  not in S3  Lizzy's Downloads pages 1 to 12   \n",
       "2  not in S3  Lizzy's Downloads pages 1 to 12   \n",
       "3  not in S3  Lizzy's Downloads pages 1 to 12   \n",
       "4  not in S3  Lizzy's Downloads pages 1 to 12   \n",
       "\n",
       "                                             Zipfile  S3_size  S3_unit  \\\n",
       "0  extract_images_p0086903ui5v_20230706203430-1@1...      NaN      NaN   \n",
       "1  extract_images_p0086903ui5v_20230706203430-1@1...      NaN      NaN   \n",
       "2  extract_images_p0086903ui5v_20230706203430-1@1...      NaN      NaN   \n",
       "3  extract_images_p0086903ui5v_20230706203430-1@1...      NaN      NaN   \n",
       "4  extract_images_p0086903ui5v_20230706203430-1@1...      NaN      NaN   \n",
       "\n",
       "               S3_dttm  \n",
       "0                       \n",
       "1                       \n",
       "2                       \n",
       "3                       \n",
       "4                       "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 3 Setup the dataframe of missing values dataframe\n",
    "import pandas as pd\n",
    "df_missing_data = pd.read_excel(\"C:/Users/Praful Bhoyar/Desktop/missing excel/s3 missing files.xlsx\")\n",
    "df_missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7fa90b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4. With zip files\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "def copy_files_based_on_dataframe(df, source_folder, destination_base_folder, exclude_extensions=None):\n",
    "    # Create 'missing_2' folder on the desktop\n",
    "    desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "    missing_folder_path = os.path.join(desktop_path, \"missing files_with zip\")\n",
    "    os.makedirs(missing_folder_path, exist_ok=True)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        filename = row['filename']\n",
    "        file_path = find_file_recursive(source_folder, filename)\n",
    "\n",
    "        if file_path and not has_extension(file_path, exclude_extensions):\n",
    "            destination_path = os.path.join(missing_folder_path, filename)\n",
    "\n",
    "            # Copy the file to the destination folder\n",
    "            shutil.copy(file_path, destination_path)\n",
    "\n",
    "def find_file_recursive(search_folder, target_filename):\n",
    "    for root, dirs, files in os.walk(search_folder):\n",
    "        if target_filename in files:\n",
    "            return os.path.join(root, target_filename)\n",
    "    return None\n",
    "\n",
    "def has_extension(file_path, extensions):\n",
    "    if extensions is None:\n",
    "        return False\n",
    "    _, file_extension = os.path.splitext(file_path)\n",
    "    return file_extension.lower() in extensions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example DataFrame with filenames in the \"filename\" column\n",
    "    df_miss_data = df_missing_data\n",
    "\n",
    "    # Set the path to the folder containing the files\n",
    "    source_folder_path = \"C:/Users/Praful Bhoyar/Desktop/extracted7z\"\n",
    "\n",
    "    # Specify the extensions to exclude (e.g., ['.zip'])\n",
    "    exclude_extensions = []\n",
    "\n",
    "    # Copy files based on DataFrame information, excluding specified extensions\n",
    "    copy_files_based_on_dataframe(df_miss_data, source_folder_path, None, exclude_extensions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eb2deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5 Without zip files\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "def copy_files_based_on_dataframe(df, source_folder, destination_base_folder, exclude_extensions=None):\n",
    "    # Create 'missing_2' folder on the desktop\n",
    "    desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "    missing_folder_path = os.path.join(desktop_path, \"missing files_without zips\")\n",
    "    os.makedirs(missing_folder_path, exist_ok=True)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        filename = row['filename']\n",
    "        file_path = find_file_recursive(source_folder, filename)\n",
    "\n",
    "        if file_path and not has_extension(file_path, exclude_extensions):\n",
    "            destination_path = os.path.join(missing_folder_path, filename)\n",
    "\n",
    "            # Copy the file to the destination folder\n",
    "            shutil.copy(file_path, destination_path)\n",
    "\n",
    "def find_file_recursive(search_folder, target_filename):\n",
    "    for root, dirs, files in os.walk(search_folder):\n",
    "        if target_filename in files:\n",
    "            return os.path.join(root, target_filename)\n",
    "    return None\n",
    "\n",
    "def has_extension(file_path, extensions):\n",
    "    if extensions is None:\n",
    "        return False\n",
    "    _, file_extension = os.path.splitext(file_path)\n",
    "    return file_extension.lower() in extensions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example DataFrame with filenames in the \"filename\" column\n",
    "    df_miss_data = df_missing_data\n",
    "\n",
    "    # Set the path to the folder containing the files\n",
    "    source_folder_path = \"C:/Users/Praful Bhoyar/Desktop/extracted7z\"\n",
    "\n",
    "    # Specify the extensions to exclude (e.g., ['.zip'])\n",
    "    exclude_extensions = ['.zip']\n",
    "\n",
    "    # Copy files based on DataFrame information, excluding specified extensions\n",
    "    copy_files_based_on_dataframe(df_miss_data, source_folder_path, None, exclude_extensions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af061ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
